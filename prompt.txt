# PROMPT 1: Update Dependencies and Configuration
I need to add Reddit API support and new scraping tools. Please perform the following:

1. Update `requirements.txt`:
   - Add `asyncpraw` (for Reddit).
   - Add `beautifulsoup4` (for easier HTML parsing with Playwright).
   - Add `lxml` (parser).

2. Update `.env.example`:
   - Add `REDDIT_CLIENT_ID=your_id`
   - Add `REDDIT_CLIENT_SECRET=your_secret`
   - Add `REDDIT_USER_AGENT=jarvis_bot_v2`

3. Update `config/settings.py`:
   - Load these new Reddit variables into the `Settings` class.

# PROMPT 2: Fix Social Agent (Real Reddit Data)
Update `agents/social_agent.py` to remove the mock data and use the real Reddit API.

Requirements:
1. Import `asyncpraw` and `settings`.
2. Initialize `asyncpraw.Reddit` using credentials from `settings`.
3. In the `run()` loop:
   - Fetch the top 10 "hot" posts from subreddits: `["Forex", "Daytrading", "algotrading"]`.
   - Combine titles and self-text.
   - Send the combined text to `groq_rotator` for sentiment analysis (Bullish/Bearish/Neutral).
   - Publish the real sentiment score to Redis channel `signals:social`.
4. Handle API errors gracefully (log and sleep).

# PROMPT 3: Fix Correlation Agent (Real Price Data)
Update `agents/correlation_agent.py` to calculate real correlations instead of hardcoded strings.

Requirements:
1. Subscribe to Redis channels `ticks:EUR/USD` and `ticks:USD/JPY` (as a proxy for DXY inverse, since DXY isn't always available on free feeds).
2. Store the last 60 minutes of price ticks for both pairs in local lists/deques.
3. Every 60 seconds:
   - Calculate the percentage change for both pairs over the last hour.
   - Logic: If EUR/USD is UP and USD/JPY is DOWN, that is "Normal" (USD weakness).
   - Logic: If EUR/USD is UP and USD/JPY is UP, that is "Divergence" (Warning).
4. Publish the calculated status to `signals:correlation`.

# PROMPT 4: Implement MyFxBook Agent (Order Book)
Create a new file `agents/orderbook_agent.py`.

Requirements:
1. Inherit from `BaseAgent` (or `VisualBaseAgent` if you prefer screenshotting, but text scraping is faster here).
2. Use `playwright` to visit: "https://www.myfxbook.com/forex-market/orderbook".
3. Wait for the table `#orderBookContainer` to load.
4. Extract the "Long %" and "Short %" for `EURUSD`, `GBPUSD`, `USDJPY`.
   - Selector hint: look for `tr` elements containing the symbol name.
5. Logic: If "Short %" > 70%, sentiment is "Bullish" (Contrarian Indicator).
6. Publish to Redis channel `signals:orderbook`.

# PROMPT 5: Implement CFTC COT Agent (Institutional Data)
Create a new file `agents/cftc_agent.py`.

Requirements:
1. Inherit from `BaseAgent`.
2. Run frequency: Once every 24 hours (check if it's Friday).
3. URL: "https://www.cftc.gov/dea/futures/deacmesf.htm" (Chicago Mercantile Exchange Short Format).
4. Use `aiohttp` to fetch the raw text data.
5. Parse the text to find "EURO FX" and "JAPANESE YEN".
6. Extract "Non-Commercial" (Speculator) positions: Long vs Short.
7. Publish the net positioning to Redis channel `signals:cftc`.

# PROMPT 6: Harden Execution Agent (Safety Checks)
Update `agents/execution_agent.py` to implement strict safety.

Requirements:
1. Update `verify_trade_visual`:
   - It MUST return `False` if the Vision AI response is negative or unclear.
   - It MUST return `False` if the screenshot fails.
   - Currently, it defaults to `True` ("Fail open") - change this to "Fail safe" (default `False`).
2. Add a `validate_spread` check before `place_order`:
   - Read the current spread from the screen or Redis.
   - If spread > 2.0 pips (for majors), return `False` and log "Spread too high".